{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.optimize\n",
        "import scipy.stats\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import cvxpy as cp\n",
        "import tqdm\n",
        "\n",
        "from collections import defaultdict\n",
        "from pathlib import Path"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-05-20T01:01:43.650Z",
          "iopub.execute_input": "2020-05-20T01:01:43.654Z",
          "iopub.status.idle": "2020-05-20T01:01:45.351Z",
          "shell.execute_reply": "2020-05-20T01:01:45.343Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle('../dataframe.pickle')"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false,
        "execution": {
          "iopub.status.busy": "2020-05-20T01:01:46.672Z",
          "iopub.execute_input": "2020-05-20T01:01:46.676Z",
          "iopub.status.idle": "2020-05-20T01:01:47.152Z",
          "shell.execute_reply": "2020-05-20T01:01:47.156Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_peaks(data):\n",
        "    peaks = np.zeros((2, 1))\n",
        "    for i in range(1, int(data.size/2) - 1):\n",
        "        if (data[1, i] > data[1, i-1] and data[1, i] > data[1, i+1]):\n",
        "            peaks = np.append(peaks, [[data[0, i]], [data[1, i]]], axis=1)\n",
        "    return peaks\n",
        "\n",
        "def normalize_and_cutoff(data, order=np.inf, cutoff=0.05):\n",
        "    data[1, :] /= np.linalg.norm(data[1, :], ord=order)\n",
        "    idxs = np.squeeze(np.argwhere(data[1, :] > cutoff))\n",
        "    return data[:, idxs]\n",
        "\n",
        "def get_peaks_dict(datas, resolution=0.1):\n",
        "    multiplier = 1 / resolution\n",
        "    peaks_dict = defaultdict(int)\n",
        "    for data in datas:\n",
        "        _, npeaks = data.shape\n",
        "        for i in range(npeaks):\n",
        "            mlt_peak_val = int(round(data[0, i] * multiplier, 0))\n",
        "            peaks_dict[mlt_peak_val] += 1\n",
        "    return peaks_dict\n",
        "\n",
        "def vectorize(datas, mapper, resolution):\n",
        "    multiplier = 1/ resolution\n",
        "    n = len(datas)\n",
        "    d = len(mapper)\n",
        "    samples = np.zeros((n, d))\n",
        "    for i in range(n):\n",
        "        data = datas[i]\n",
        "        _, nd = data.shape\n",
        "        for j in range(nd):\n",
        "            peak = int(round(data[0, j] * multiplier, 0))\n",
        "            if peak in mapper:\n",
        "                samples[i, mapper[peak]] = max(data[1, j], samples[i, mapper[peak]])\n",
        "                #samples[i, mapper[peak]] += data[1, j]\n",
        "    return samples\n",
        "\n",
        "def normalize_and_vectorize(\n",
        "      data_list, \n",
        "      order=np.inf, \n",
        "      cutoff=0.05, \n",
        "      resolution=0.1, \n",
        "      min_peak_occur=2):\n",
        "    peaks_data = [find_peaks(data) for data in data_list]\n",
        "    normalized_data = [normalize_and_cutoff(d, order, cutoff) for d in peaks_data]\n",
        "    peaks_dict = get_peaks_dict(normalized_data, resolution)\n",
        "    peaks_mapper = dict()\n",
        "    peaks = [key for key in peaks_dict.keys() if peaks_dict[key] >= min_peak_occur]\n",
        "    for i in range(len(peaks)):\n",
        "        peaks_mapper[peaks[i]] = i\n",
        "    idx2peak = {v:k for k, v in peaks_mapper.items()}\n",
        "    peak_seq = np.array([idx2peak[i] for i in range(len(idx2peak))]) * resolution\n",
        "    vectorized_data = vectorize(normalized_data, peaks_mapper, resolution)\n",
        "    return vectorized_data, peak_seq"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-05-20T01:01:48.697Z",
          "iopub.execute_input": "2020-05-20T01:01:48.701Z",
          "iopub.status.idle": "2020-05-20T01:01:48.707Z",
          "shell.execute_reply": "2020-05-20T01:01:48.716Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cutoff=0.001\n",
        "resolution=0.1\n",
        "min_peak_occur=2\n",
        "order=np.inf\n",
        "vec_data, peak_seq = normalize_and_vectorize(\n",
        "  df['mass_spec'], order, cutoff, resolution, min_peak_occur)\n",
        "df['vec'] = list(vec_data)\n",
        "npeaks = len(peak_seq)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-20T01:01:51.189Z",
          "iopub.execute_input": "2020-05-20T01:01:51.193Z",
          "iopub.status.idle": "2020-05-20T01:01:52.627Z",
          "shell.execute_reply": "2020-05-20T01:01:52.622Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "for i, peak in enumerate(peak_seq):\n",
        "  if abs(peak-151.0) < 1e-5:\n",
        "    idx = i"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-20T01:01:54.324Z",
          "iopub.execute_input": "2020-05-20T01:01:54.329Z",
          "iopub.status.idle": "2020-05-20T01:01:54.337Z",
          "shell.execute_reply": "2020-05-20T01:01:54.346Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cvx_opt(A, Y, n=npeaks):\n",
        "  x = cp.Variable((2, n))\n",
        "  cost = cp.sum_squares(A @ x - Y)\n",
        "  objective = cp.Minimize(cost)\n",
        "  constraints = [x >= 0]\n",
        "  prob = cp.Problem(objective, constraints)\n",
        "  prob.solve(eps_rel=1e-12, eps_abs=1e-12)\n",
        "  return x.value.T"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-20T01:00:25.669Z",
          "iopub.execute_input": "2020-05-20T01:00:25.673Z",
          "iopub.status.idle": "2020-05-20T01:00:25.679Z",
          "shell.execute_reply": "2020-05-20T01:00:25.686Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def deconvolution(fld):\n",
        "  loc = df['file'].str.find(f'Y{fld}_') != -1\n",
        "  A = df.loc[loc, ['gfap_positive_count', 'gfap_negative_count']].values\n",
        "  Y = np.array(df.loc[loc, ['vec']]['vec'].tolist())\n",
        "  Y = Y / Y[:, idx].reshape((-1, 1))\n",
        "  result = cvx_opt(A, Y)\n",
        "  pos = result[:, 0]/result[:, 0].max()\n",
        "  neg = result[:, 1]/result[:, 1].max()\n",
        "  return pos, neg\n",
        "\n",
        "positives = []\n",
        "negatives = []\n",
        "for i in tqdm.trange(1, 11):\n",
        "  pos, neg = deconvolution(i)\n",
        "  positives.append(pos)\n",
        "  negatives.append(neg)\n",
        "results = np.vstack([peak_seq] + positives + negatives).T\n",
        "\n",
        "result_df = pd.DataFrame(results, \n",
        "    columns=(['m/z'] + \n",
        "             [f'gfap_positive_Y{i}' for i in range(1, 11)] + \n",
        "             [f'gfap_negative_Y{i}' for i in range(1, 11)]))\n",
        "result_df.to_csv('cell_count_int_std.csv')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [20:00<00:00, 120.08s/it]\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-12T04:09:21.829Z",
          "iopub.execute_input": "2020-05-12T04:09:21.840Z",
          "iopub.status.idle": "2020-05-12T03:48:51.694Z",
          "shell.execute_reply": "2020-05-12T03:48:51.714Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def deconvolution_all(df):\n",
        "  A = df[['gfap_positive_count', 'gfap_negative_count']].values\n",
        "  Y = np.array(df['vec'].tolist())\n",
        "  Y = Y / Y[:, idx].reshape((-1, 1))\n",
        "  result = cvx_opt(A, Y)\n",
        "  pos = result[:, 0]/result[:, 0].max()\n",
        "  neg = result[:, 1]/result[:, 1].max()\n",
        "  return pos, neg\n",
        "\n",
        "pos, neg = deconvolution_all(df)\n",
        "results = np.vstack([peak_seq, pos, neg]).T\n",
        "\n",
        "result_df = pd.DataFrame(results, \n",
        "    columns=('m/z', 'gfap_positive', 'gfap_negative'))\n",
        "result_df.to_csv('cell_count_all_samples.csv')"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-20T01:17:36.480Z",
          "iopub.execute_input": "2020-05-20T01:17:36.482Z",
          "iopub.status.idle": "2020-05-20T01:18:05.426Z",
          "shell.execute_reply": "2020-05-20T01:18:05.422Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('cell_count_int_std.csv')\n",
        "pos = [f'gfap_positive_Y{i + 1}' for i in range(10)]\n",
        "neg = [f'gfap_negative_Y{i + 1}' for i in range(10)]\n",
        "pos_samples = df[pos].values\n",
        "neg_samples = df[neg].values\n",
        "t_stat, p_val = sp.stats.ttest_ind(pos_samples, neg_samples, axis=1)\n",
        "df['t-stat'] = t_stat\n",
        "df['p-value'] = p_val\n",
        "df.to_csv('cell_count_int_std_p_value.csv')"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-15T03:48:58.594Z",
          "iopub.execute_input": "2020-05-15T03:48:58.598Z",
          "iopub.status.idle": "2020-05-15T03:48:59.032Z",
          "shell.execute_reply": "2020-05-15T03:48:59.035Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clip(array, eps=1e-14):\n",
        "  array[array < eps] = 0\n",
        "  return array\n",
        "df = pd.read_csv('cell_count_int_std.csv')\n",
        "pos = [f'gfap_positive_Y{i + 1}' for i in range(10)]\n",
        "neg = [f'gfap_negative_Y{i + 1}' for i in range(10)]\n",
        "pos_samples = clip(df[pos].values)\n",
        "neg_samples = clip(df[neg].values)\n",
        "\n",
        "test_statistics, p_val = list(zip(*(\n",
        "  sp.stats.ranksums(pos, neg) \n",
        "  for pos, neg in zip(pos_samples, neg_samples))))\n",
        "df['ranksums_test_statistics'] = test_statistics\n",
        "df['ranksums_p-value'] = p_val\n",
        "df.to_csv('cell_count_int_std_ranksums.csv')"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {
        "collapsed": true,
        "outputExpanded": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-05-18T04:13:20.191Z",
          "iopub.execute_input": "2020-05-18T04:13:20.199Z",
          "iopub.status.idle": "2020-05-18T04:13:21.344Z",
          "shell.execute_reply": "2020-05-18T04:13:21.348Z"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.22.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
